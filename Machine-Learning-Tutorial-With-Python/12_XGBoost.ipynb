{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "12.XGBoost.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNJegBOa+K15DJIvm2jg7wh"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkc8yG5duNAr"
      },
      "source": [
        "# XGBoost(eXtra Gradient Boost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRvctZaGcVPh"
      },
      "source": [
        "파이썬 래퍼 XGBoost 적용 - 위스콘신 Breast Cancer 데이터 셋 로딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "S5Zu0ZtfclNr",
        "outputId": "71bb3b90-372a-484b-8be4-f955c80450a7"
      },
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import  load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dataset = load_breast_cancer()\n",
        "X_features= dataset.data\n",
        "y_label = dataset.target\n",
        "\n",
        "cancer_df = pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
        "cancer_df['target']= y_label\n",
        "cancer_df.head(3)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.8</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.6</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.9</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.8</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.0</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.5</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0        17.99         10.38  ...                  0.11890       0\n",
              "1        20.57         17.77  ...                  0.08902       0\n",
              "2        19.69         21.25  ...                  0.08758       0\n",
              "\n",
              "[3 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9DgNrdJ0Pnf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d36c05a7-f7b8-4a37-8db8-997fac7aaadf"
      },
      "source": [
        "print(dataset.target_names)\n",
        "print(cancer_df['target'].value_counts())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['malignant' 'benign']\n",
            "1    357\n",
            "0    212\n",
            "Name: target, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIx97ekyunkM",
        "outputId": "57751e60-a249-4eca-a0fb-01131fa143d9"
      },
      "source": [
        "# 전체 데이터 중 80%는 학습용 데이터, 20%는 테스트용 데이터 추출\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_features, y_label,\n",
        "                                                    test_size = 0.2, random_state=156)\n",
        "\n",
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(455, 30) (114, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xdad5orvbzL"
      },
      "source": [
        "학습과 예측 데이터 세트를 DMatrix로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IT5hE-LPvbTs"
      },
      "source": [
        "dtrain = xgb.DMatrix(data = X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(data = X_test, label=y_test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3SpEM3Iv1a8"
      },
      "source": [
        "하이퍼 파라미터 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eURssf_Fv0c1"
      },
      "source": [
        "params = {\n",
        "    'max_depth' : 3,\n",
        "    'eta' : 0.1,\n",
        "    'objective' : 'binary:logistic',\n",
        "    'eval_metric' : 'logloss',\n",
        "    'early_stoppings' : 100\n",
        "    }\n",
        "\n",
        "num_rounds = 400"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMmSCoICy859"
      },
      "source": [
        "주어진 하이퍼 파라미터와 early stopping 파라미터를 train() 함수의 파라미터로 전달하고 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hITGuzFXy72Z",
        "outputId": "b1d21207-7525-45d5-bd0a-c1f7da0e8ae9"
      },
      "source": [
        "# train 데이터 셋은 'train', evaluation(test) 데이터 셋은 'eval'\n",
        "wlist = [(dtrain,\"train\"),(dtest, 'eval')]\n",
        "\n",
        "# 하이퍼 파라미터와 early stopping 파라미터를 train() 함수와 파라미터로 전달\n",
        "xgb_model = xgb.train(params= params, dtrain=dtrain, num_boost_round=num_rounds,\n",
        "                      evals=wlist)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\ttrain-logloss:0.609688\teval-logloss:0.61352\n",
            "[1]\ttrain-logloss:0.540803\teval-logloss:0.547843\n",
            "[2]\ttrain-logloss:0.483753\teval-logloss:0.494248\n",
            "[3]\ttrain-logloss:0.434457\teval-logloss:0.447986\n",
            "[4]\ttrain-logloss:0.39055\teval-logloss:0.409109\n",
            "[5]\ttrain-logloss:0.354146\teval-logloss:0.374977\n",
            "[6]\ttrain-logloss:0.321222\teval-logloss:0.345714\n",
            "[7]\ttrain-logloss:0.292593\teval-logloss:0.320529\n",
            "[8]\ttrain-logloss:0.267467\teval-logloss:0.29721\n",
            "[9]\ttrain-logloss:0.245153\teval-logloss:0.277991\n",
            "[10]\ttrain-logloss:0.225694\teval-logloss:0.260302\n",
            "[11]\ttrain-logloss:0.207938\teval-logloss:0.246037\n",
            "[12]\ttrain-logloss:0.192184\teval-logloss:0.231556\n",
            "[13]\ttrain-logloss:0.177916\teval-logloss:0.22005\n",
            "[14]\ttrain-logloss:0.165222\teval-logloss:0.208572\n",
            "[15]\ttrain-logloss:0.153622\teval-logloss:0.199993\n",
            "[16]\ttrain-logloss:0.14333\teval-logloss:0.190118\n",
            "[17]\ttrain-logloss:0.133985\teval-logloss:0.181818\n",
            "[18]\ttrain-logloss:0.125599\teval-logloss:0.174729\n",
            "[19]\ttrain-logloss:0.117286\teval-logloss:0.167657\n",
            "[20]\ttrain-logloss:0.109688\teval-logloss:0.158202\n",
            "[21]\ttrain-logloss:0.102975\teval-logloss:0.154725\n",
            "[22]\ttrain-logloss:0.097067\teval-logloss:0.148947\n",
            "[23]\ttrain-logloss:0.091428\teval-logloss:0.143308\n",
            "[24]\ttrain-logloss:0.086335\teval-logloss:0.136344\n",
            "[25]\ttrain-logloss:0.081311\teval-logloss:0.132778\n",
            "[26]\ttrain-logloss:0.076857\teval-logloss:0.127912\n",
            "[27]\ttrain-logloss:0.072836\teval-logloss:0.125263\n",
            "[28]\ttrain-logloss:0.069248\teval-logloss:0.119978\n",
            "[29]\ttrain-logloss:0.065549\teval-logloss:0.116412\n",
            "[30]\ttrain-logloss:0.062414\teval-logloss:0.114502\n",
            "[31]\ttrain-logloss:0.059591\teval-logloss:0.112572\n",
            "[32]\ttrain-logloss:0.057096\teval-logloss:0.11154\n",
            "[33]\ttrain-logloss:0.054407\teval-logloss:0.108681\n",
            "[34]\ttrain-logloss:0.052036\teval-logloss:0.106681\n",
            "[35]\ttrain-logloss:0.049751\teval-logloss:0.104207\n",
            "[36]\ttrain-logloss:0.04775\teval-logloss:0.102962\n",
            "[37]\ttrain-logloss:0.045853\teval-logloss:0.100576\n",
            "[38]\ttrain-logloss:0.044015\teval-logloss:0.098683\n",
            "[39]\ttrain-logloss:0.042263\teval-logloss:0.096444\n",
            "[40]\ttrain-logloss:0.040649\teval-logloss:0.095869\n",
            "[41]\ttrain-logloss:0.039126\teval-logloss:0.094242\n",
            "[42]\ttrain-logloss:0.037377\teval-logloss:0.094715\n",
            "[43]\ttrain-logloss:0.036106\teval-logloss:0.094272\n",
            "[44]\ttrain-logloss:0.034941\teval-logloss:0.093894\n",
            "[45]\ttrain-logloss:0.033654\teval-logloss:0.094184\n",
            "[46]\ttrain-logloss:0.032528\teval-logloss:0.09402\n",
            "[47]\ttrain-logloss:0.031485\teval-logloss:0.09236\n",
            "[48]\ttrain-logloss:0.030389\teval-logloss:0.093012\n",
            "[49]\ttrain-logloss:0.029467\teval-logloss:0.091273\n",
            "[50]\ttrain-logloss:0.028545\teval-logloss:0.090051\n",
            "[51]\ttrain-logloss:0.027525\teval-logloss:0.089605\n",
            "[52]\ttrain-logloss:0.026555\teval-logloss:0.089577\n",
            "[53]\ttrain-logloss:0.025682\teval-logloss:0.090703\n",
            "[54]\ttrain-logloss:0.025004\teval-logloss:0.089579\n",
            "[55]\ttrain-logloss:0.024297\teval-logloss:0.090357\n",
            "[56]\ttrain-logloss:0.023574\teval-logloss:0.091587\n",
            "[57]\ttrain-logloss:0.022965\teval-logloss:0.091527\n",
            "[58]\ttrain-logloss:0.022488\teval-logloss:0.091986\n",
            "[59]\ttrain-logloss:0.021854\teval-logloss:0.091951\n",
            "[60]\ttrain-logloss:0.021316\teval-logloss:0.091939\n",
            "[61]\ttrain-logloss:0.020794\teval-logloss:0.091461\n",
            "[62]\ttrain-logloss:0.020218\teval-logloss:0.090311\n",
            "[63]\ttrain-logloss:0.019701\teval-logloss:0.089407\n",
            "[64]\ttrain-logloss:0.01918\teval-logloss:0.089719\n",
            "[65]\ttrain-logloss:0.018724\teval-logloss:0.089743\n",
            "[66]\ttrain-logloss:0.018325\teval-logloss:0.089622\n",
            "[67]\ttrain-logloss:0.017867\teval-logloss:0.088734\n",
            "[68]\ttrain-logloss:0.017598\teval-logloss:0.088621\n",
            "[69]\ttrain-logloss:0.017243\teval-logloss:0.089739\n",
            "[70]\ttrain-logloss:0.01688\teval-logloss:0.089981\n",
            "[71]\ttrain-logloss:0.016641\teval-logloss:0.089782\n",
            "[72]\ttrain-logloss:0.016287\teval-logloss:0.089584\n",
            "[73]\ttrain-logloss:0.015983\teval-logloss:0.089533\n",
            "[74]\ttrain-logloss:0.015658\teval-logloss:0.088748\n",
            "[75]\ttrain-logloss:0.015393\teval-logloss:0.088597\n",
            "[76]\ttrain-logloss:0.015151\teval-logloss:0.08812\n",
            "[77]\ttrain-logloss:0.01488\teval-logloss:0.088396\n",
            "[78]\ttrain-logloss:0.014637\teval-logloss:0.088736\n",
            "[79]\ttrain-logloss:0.014491\teval-logloss:0.088153\n",
            "[80]\ttrain-logloss:0.014185\teval-logloss:0.087577\n",
            "[81]\ttrain-logloss:0.014005\teval-logloss:0.087412\n",
            "[82]\ttrain-logloss:0.013772\teval-logloss:0.08849\n",
            "[83]\ttrain-logloss:0.013568\teval-logloss:0.088575\n",
            "[84]\ttrain-logloss:0.013414\teval-logloss:0.08807\n",
            "[85]\ttrain-logloss:0.013253\teval-logloss:0.087641\n",
            "[86]\ttrain-logloss:0.013109\teval-logloss:0.087416\n",
            "[87]\ttrain-logloss:0.012926\teval-logloss:0.087611\n",
            "[88]\ttrain-logloss:0.012714\teval-logloss:0.087065\n",
            "[89]\ttrain-logloss:0.012544\teval-logloss:0.08727\n",
            "[90]\ttrain-logloss:0.012353\teval-logloss:0.087161\n",
            "[91]\ttrain-logloss:0.012226\teval-logloss:0.086962\n",
            "[92]\ttrain-logloss:0.012065\teval-logloss:0.087166\n",
            "[93]\ttrain-logloss:0.011927\teval-logloss:0.087067\n",
            "[94]\ttrain-logloss:0.011821\teval-logloss:0.086592\n",
            "[95]\ttrain-logloss:0.011649\teval-logloss:0.086116\n",
            "[96]\ttrain-logloss:0.011482\teval-logloss:0.087139\n",
            "[97]\ttrain-logloss:0.01136\teval-logloss:0.086768\n",
            "[98]\ttrain-logloss:0.011239\teval-logloss:0.086694\n",
            "[99]\ttrain-logloss:0.011132\teval-logloss:0.086547\n",
            "[100]\ttrain-logloss:0.011002\teval-logloss:0.086498\n",
            "[101]\ttrain-logloss:0.010852\teval-logloss:0.08641\n",
            "[102]\ttrain-logloss:0.010755\teval-logloss:0.086288\n",
            "[103]\ttrain-logloss:0.010636\teval-logloss:0.086258\n",
            "[104]\ttrain-logloss:0.0105\teval-logloss:0.086835\n",
            "[105]\ttrain-logloss:0.010395\teval-logloss:0.086767\n",
            "[106]\ttrain-logloss:0.010305\teval-logloss:0.087321\n",
            "[107]\ttrain-logloss:0.010197\teval-logloss:0.087304\n",
            "[108]\ttrain-logloss:0.010072\teval-logloss:0.08728\n",
            "[109]\ttrain-logloss:0.01\teval-logloss:0.087298\n",
            "[110]\ttrain-logloss:0.009914\teval-logloss:0.087289\n",
            "[111]\ttrain-logloss:0.009798\teval-logloss:0.088002\n",
            "[112]\ttrain-logloss:0.00971\teval-logloss:0.087936\n",
            "[113]\ttrain-logloss:0.009628\teval-logloss:0.087843\n",
            "[114]\ttrain-logloss:0.009558\teval-logloss:0.088066\n",
            "[115]\ttrain-logloss:0.009483\teval-logloss:0.087649\n",
            "[116]\ttrain-logloss:0.009416\teval-logloss:0.087298\n",
            "[117]\ttrain-logloss:0.009306\teval-logloss:0.087799\n",
            "[118]\ttrain-logloss:0.009228\teval-logloss:0.087751\n",
            "[119]\ttrain-logloss:0.009154\teval-logloss:0.08768\n",
            "[120]\ttrain-logloss:0.009118\teval-logloss:0.087626\n",
            "[121]\ttrain-logloss:0.009016\teval-logloss:0.08757\n",
            "[122]\ttrain-logloss:0.008972\teval-logloss:0.087547\n",
            "[123]\ttrain-logloss:0.008904\teval-logloss:0.087156\n",
            "[124]\ttrain-logloss:0.008837\teval-logloss:0.08767\n",
            "[125]\ttrain-logloss:0.008803\teval-logloss:0.087737\n",
            "[126]\ttrain-logloss:0.008709\teval-logloss:0.088275\n",
            "[127]\ttrain-logloss:0.008645\teval-logloss:0.088309\n",
            "[128]\ttrain-logloss:0.008613\teval-logloss:0.088266\n",
            "[129]\ttrain-logloss:0.008555\teval-logloss:0.087886\n",
            "[130]\ttrain-logloss:0.008463\teval-logloss:0.088861\n",
            "[131]\ttrain-logloss:0.008416\teval-logloss:0.088675\n",
            "[132]\ttrain-logloss:0.008385\teval-logloss:0.088743\n",
            "[133]\ttrain-logloss:0.0083\teval-logloss:0.089218\n",
            "[134]\ttrain-logloss:0.00827\teval-logloss:0.089179\n",
            "[135]\ttrain-logloss:0.008218\teval-logloss:0.088821\n",
            "[136]\ttrain-logloss:0.008157\teval-logloss:0.088512\n",
            "[137]\ttrain-logloss:0.008076\teval-logloss:0.08848\n",
            "[138]\ttrain-logloss:0.008047\teval-logloss:0.088386\n",
            "[139]\ttrain-logloss:0.007973\teval-logloss:0.089145\n",
            "[140]\ttrain-logloss:0.007946\teval-logloss:0.08911\n",
            "[141]\ttrain-logloss:0.007898\teval-logloss:0.088765\n",
            "[142]\ttrain-logloss:0.007872\teval-logloss:0.088678\n",
            "[143]\ttrain-logloss:0.007847\teval-logloss:0.088389\n",
            "[144]\ttrain-logloss:0.007776\teval-logloss:0.089271\n",
            "[145]\ttrain-logloss:0.007752\teval-logloss:0.089238\n",
            "[146]\ttrain-logloss:0.007728\teval-logloss:0.089139\n",
            "[147]\ttrain-logloss:0.007689\teval-logloss:0.088907\n",
            "[148]\ttrain-logloss:0.007621\teval-logloss:0.089416\n",
            "[149]\ttrain-logloss:0.007598\teval-logloss:0.089388\n",
            "[150]\ttrain-logloss:0.007575\teval-logloss:0.089108\n",
            "[151]\ttrain-logloss:0.007521\teval-logloss:0.088735\n",
            "[152]\ttrain-logloss:0.007498\teval-logloss:0.088717\n",
            "[153]\ttrain-logloss:0.007464\teval-logloss:0.088484\n",
            "[154]\ttrain-logloss:0.00741\teval-logloss:0.088471\n",
            "[155]\ttrain-logloss:0.007389\teval-logloss:0.088545\n",
            "[156]\ttrain-logloss:0.007367\teval-logloss:0.088521\n",
            "[157]\ttrain-logloss:0.007345\teval-logloss:0.088547\n",
            "[158]\ttrain-logloss:0.007323\teval-logloss:0.088275\n",
            "[159]\ttrain-logloss:0.007303\teval-logloss:0.0883\n",
            "[160]\ttrain-logloss:0.007282\teval-logloss:0.08828\n",
            "[161]\ttrain-logloss:0.007261\teval-logloss:0.088013\n",
            "[162]\ttrain-logloss:0.007241\teval-logloss:0.087758\n",
            "[163]\ttrain-logloss:0.007221\teval-logloss:0.087784\n",
            "[164]\ttrain-logloss:0.0072\teval-logloss:0.087777\n",
            "[165]\ttrain-logloss:0.00718\teval-logloss:0.087517\n",
            "[166]\ttrain-logloss:0.007161\teval-logloss:0.087542\n",
            "[167]\ttrain-logloss:0.007142\teval-logloss:0.087642\n",
            "[168]\ttrain-logloss:0.007122\teval-logloss:0.08739\n",
            "[169]\ttrain-logloss:0.007103\teval-logloss:0.087377\n",
            "[170]\ttrain-logloss:0.007084\teval-logloss:0.087298\n",
            "[171]\ttrain-logloss:0.007065\teval-logloss:0.087368\n",
            "[172]\ttrain-logloss:0.007047\teval-logloss:0.087395\n",
            "[173]\ttrain-logloss:0.007028\teval-logloss:0.087385\n",
            "[174]\ttrain-logloss:0.007009\teval-logloss:0.087132\n",
            "[175]\ttrain-logloss:0.006991\teval-logloss:0.087159\n",
            "[176]\ttrain-logloss:0.006973\teval-logloss:0.086955\n",
            "[177]\ttrain-logloss:0.006955\teval-logloss:0.087053\n",
            "[178]\ttrain-logloss:0.006937\teval-logloss:0.08697\n",
            "[179]\ttrain-logloss:0.00692\teval-logloss:0.086973\n",
            "[180]\ttrain-logloss:0.006901\teval-logloss:0.087038\n",
            "[181]\ttrain-logloss:0.006884\teval-logloss:0.086799\n",
            "[182]\ttrain-logloss:0.006866\teval-logloss:0.086826\n",
            "[183]\ttrain-logloss:0.006849\teval-logloss:0.086582\n",
            "[184]\ttrain-logloss:0.006831\teval-logloss:0.086588\n",
            "[185]\ttrain-logloss:0.006815\teval-logloss:0.086614\n",
            "[186]\ttrain-logloss:0.006798\teval-logloss:0.086372\n",
            "[187]\ttrain-logloss:0.006781\teval-logloss:0.086369\n",
            "[188]\ttrain-logloss:0.006764\teval-logloss:0.086297\n",
            "[189]\ttrain-logloss:0.006747\teval-logloss:0.086104\n",
            "[190]\ttrain-logloss:0.00673\teval-logloss:0.086023\n",
            "[191]\ttrain-logloss:0.006714\teval-logloss:0.08605\n",
            "[192]\ttrain-logloss:0.006698\teval-logloss:0.086149\n",
            "[193]\ttrain-logloss:0.006682\teval-logloss:0.085916\n",
            "[194]\ttrain-logloss:0.006666\teval-logloss:0.085915\n",
            "[195]\ttrain-logloss:0.00665\teval-logloss:0.085984\n",
            "[196]\ttrain-logloss:0.006634\teval-logloss:0.086012\n",
            "[197]\ttrain-logloss:0.006618\teval-logloss:0.085922\n",
            "[198]\ttrain-logloss:0.006603\teval-logloss:0.085853\n",
            "[199]\ttrain-logloss:0.006587\teval-logloss:0.085874\n",
            "[200]\ttrain-logloss:0.006572\teval-logloss:0.085888\n",
            "[201]\ttrain-logloss:0.006556\teval-logloss:0.08595\n",
            "[202]\ttrain-logloss:0.006542\teval-logloss:0.08573\n",
            "[203]\ttrain-logloss:0.006527\teval-logloss:0.08573\n",
            "[204]\ttrain-logloss:0.006512\teval-logloss:0.085753\n",
            "[205]\ttrain-logloss:0.006497\teval-logloss:0.085821\n",
            "[206]\ttrain-logloss:0.006483\teval-logloss:0.08584\n",
            "[207]\ttrain-logloss:0.006469\teval-logloss:0.085776\n",
            "[208]\ttrain-logloss:0.006455\teval-logloss:0.085686\n",
            "[209]\ttrain-logloss:0.00644\teval-logloss:0.08571\n",
            "[210]\ttrain-logloss:0.006427\teval-logloss:0.085806\n",
            "[211]\ttrain-logloss:0.006413\teval-logloss:0.085593\n",
            "[212]\ttrain-logloss:0.006399\teval-logloss:0.085801\n",
            "[213]\ttrain-logloss:0.006385\teval-logloss:0.085807\n",
            "[214]\ttrain-logloss:0.006372\teval-logloss:0.085744\n",
            "[215]\ttrain-logloss:0.006359\teval-logloss:0.085658\n",
            "[216]\ttrain-logloss:0.006345\teval-logloss:0.085843\n",
            "[217]\ttrain-logloss:0.006332\teval-logloss:0.085632\n",
            "[218]\ttrain-logloss:0.006319\teval-logloss:0.085726\n",
            "[219]\ttrain-logloss:0.006306\teval-logloss:0.085783\n",
            "[220]\ttrain-logloss:0.006293\teval-logloss:0.085791\n",
            "[221]\ttrain-logloss:0.00628\teval-logloss:0.085817\n",
            "[222]\ttrain-logloss:0.006268\teval-logloss:0.085757\n",
            "[223]\ttrain-logloss:0.006255\teval-logloss:0.085674\n",
            "[224]\ttrain-logloss:0.006242\teval-logloss:0.08586\n",
            "[225]\ttrain-logloss:0.00623\teval-logloss:0.085871\n",
            "[226]\ttrain-logloss:0.006218\teval-logloss:0.085927\n",
            "[227]\ttrain-logloss:0.006206\teval-logloss:0.085954\n",
            "[228]\ttrain-logloss:0.006194\teval-logloss:0.085874\n",
            "[229]\ttrain-logloss:0.006182\teval-logloss:0.086057\n",
            "[230]\ttrain-logloss:0.00617\teval-logloss:0.086002\n",
            "[231]\ttrain-logloss:0.006158\teval-logloss:0.085922\n",
            "[232]\ttrain-logloss:0.006147\teval-logloss:0.086102\n",
            "[233]\ttrain-logloss:0.006135\teval-logloss:0.086115\n",
            "[234]\ttrain-logloss:0.006124\teval-logloss:0.086169\n",
            "[235]\ttrain-logloss:0.006112\teval-logloss:0.086263\n",
            "[236]\ttrain-logloss:0.006101\teval-logloss:0.086291\n",
            "[237]\ttrain-logloss:0.00609\teval-logloss:0.086217\n",
            "[238]\ttrain-logloss:0.006079\teval-logloss:0.086395\n",
            "[239]\ttrain-logloss:0.006068\teval-logloss:0.086342\n",
            "[240]\ttrain-logloss:0.006057\teval-logloss:0.08618\n",
            "[241]\ttrain-logloss:0.006046\teval-logloss:0.086195\n",
            "[242]\ttrain-logloss:0.006036\teval-logloss:0.086248\n",
            "[243]\ttrain-logloss:0.006025\teval-logloss:0.086263\n",
            "[244]\ttrain-logloss:0.006014\teval-logloss:0.086293\n",
            "[245]\ttrain-logloss:0.006004\teval-logloss:0.086222\n",
            "[246]\ttrain-logloss:0.005993\teval-logloss:0.086398\n",
            "[247]\ttrain-logloss:0.005983\teval-logloss:0.086347\n",
            "[248]\ttrain-logloss:0.005972\teval-logloss:0.086276\n",
            "[249]\ttrain-logloss:0.005962\teval-logloss:0.086448\n",
            "[250]\ttrain-logloss:0.005952\teval-logloss:0.086294\n",
            "[251]\ttrain-logloss:0.005942\teval-logloss:0.086312\n",
            "[252]\ttrain-logloss:0.005932\teval-logloss:0.086364\n",
            "[253]\ttrain-logloss:0.005922\teval-logloss:0.086394\n",
            "[254]\ttrain-logloss:0.005912\teval-logloss:0.08649\n",
            "[255]\ttrain-logloss:0.005903\teval-logloss:0.086441\n",
            "[256]\ttrain-logloss:0.005893\teval-logloss:0.08629\n",
            "[257]\ttrain-logloss:0.005883\teval-logloss:0.086459\n",
            "[258]\ttrain-logloss:0.005874\teval-logloss:0.086391\n",
            "[259]\ttrain-logloss:0.005864\teval-logloss:0.086441\n",
            "[260]\ttrain-logloss:0.005855\teval-logloss:0.086461\n",
            "[261]\ttrain-logloss:0.005845\teval-logloss:0.086491\n",
            "[262]\ttrain-logloss:0.005836\teval-logloss:0.086445\n",
            "[263]\ttrain-logloss:0.005827\teval-logloss:0.086466\n",
            "[264]\ttrain-logloss:0.005818\teval-logloss:0.086319\n",
            "[265]\ttrain-logloss:0.005809\teval-logloss:0.086488\n",
            "[266]\ttrain-logloss:0.0058\teval-logloss:0.086538\n",
            "[267]\ttrain-logloss:0.005791\teval-logloss:0.086471\n",
            "[268]\ttrain-logloss:0.005782\teval-logloss:0.086501\n",
            "[269]\ttrain-logloss:0.005773\teval-logloss:0.086522\n",
            "[270]\ttrain-logloss:0.005764\teval-logloss:0.086689\n",
            "[271]\ttrain-logloss:0.005755\teval-logloss:0.086738\n",
            "[272]\ttrain-logloss:0.005747\teval-logloss:0.086829\n",
            "[273]\ttrain-logloss:0.005738\teval-logloss:0.086684\n",
            "[274]\ttrain-logloss:0.005729\teval-logloss:0.08664\n",
            "[275]\ttrain-logloss:0.005721\teval-logloss:0.086496\n",
            "[276]\ttrain-logloss:0.005712\teval-logloss:0.086355\n",
            "[277]\ttrain-logloss:0.005704\teval-logloss:0.086519\n",
            "[278]\ttrain-logloss:0.005696\teval-logloss:0.086567\n",
            "[279]\ttrain-logloss:0.005687\teval-logloss:0.08659\n",
            "[280]\ttrain-logloss:0.005679\teval-logloss:0.086679\n",
            "[281]\ttrain-logloss:0.005671\teval-logloss:0.086637\n",
            "[282]\ttrain-logloss:0.005663\teval-logloss:0.086499\n",
            "[283]\ttrain-logloss:0.005655\teval-logloss:0.086356\n",
            "[284]\ttrain-logloss:0.005646\teval-logloss:0.086405\n",
            "[285]\ttrain-logloss:0.005639\teval-logloss:0.086429\n",
            "[286]\ttrain-logloss:0.005631\teval-logloss:0.086456\n",
            "[287]\ttrain-logloss:0.005623\teval-logloss:0.086504\n",
            "[288]\ttrain-logloss:0.005615\teval-logloss:0.08637\n",
            "[289]\ttrain-logloss:0.005608\teval-logloss:0.086457\n",
            "[290]\ttrain-logloss:0.0056\teval-logloss:0.086453\n",
            "[291]\ttrain-logloss:0.005593\teval-logloss:0.086322\n",
            "[292]\ttrain-logloss:0.005585\teval-logloss:0.086284\n",
            "[293]\ttrain-logloss:0.005577\teval-logloss:0.086148\n",
            "[294]\ttrain-logloss:0.00557\teval-logloss:0.086196\n",
            "[295]\ttrain-logloss:0.005563\teval-logloss:0.086221\n",
            "[296]\ttrain-logloss:0.005556\teval-logloss:0.086308\n",
            "[297]\ttrain-logloss:0.005548\teval-logloss:0.086178\n",
            "[298]\ttrain-logloss:0.005541\teval-logloss:0.086263\n",
            "[299]\ttrain-logloss:0.005534\teval-logloss:0.086131\n",
            "[300]\ttrain-logloss:0.005526\teval-logloss:0.086179\n",
            "[301]\ttrain-logloss:0.005519\teval-logloss:0.086052\n",
            "[302]\ttrain-logloss:0.005512\teval-logloss:0.086016\n",
            "[303]\ttrain-logloss:0.005505\teval-logloss:0.086101\n",
            "[304]\ttrain-logloss:0.005498\teval-logloss:0.085977\n",
            "[305]\ttrain-logloss:0.005491\teval-logloss:0.086059\n",
            "[306]\ttrain-logloss:0.005484\teval-logloss:0.085971\n",
            "[307]\ttrain-logloss:0.005478\teval-logloss:0.085998\n",
            "[308]\ttrain-logloss:0.005471\teval-logloss:0.085998\n",
            "[309]\ttrain-logloss:0.005464\teval-logloss:0.085877\n",
            "[310]\ttrain-logloss:0.005457\teval-logloss:0.085923\n",
            "[311]\ttrain-logloss:0.00545\teval-logloss:0.085948\n",
            "[312]\ttrain-logloss:0.005444\teval-logloss:0.086028\n",
            "[313]\ttrain-logloss:0.005437\teval-logloss:0.086112\n",
            "[314]\ttrain-logloss:0.00543\teval-logloss:0.085989\n",
            "[315]\ttrain-logloss:0.005424\teval-logloss:0.085903\n",
            "[316]\ttrain-logloss:0.005417\teval-logloss:0.085949\n",
            "[317]\ttrain-logloss:0.005411\teval-logloss:0.085977\n",
            "[318]\ttrain-logloss:0.005404\teval-logloss:0.086002\n",
            "[319]\ttrain-logloss:0.005398\teval-logloss:0.085883\n",
            "[320]\ttrain-logloss:0.005392\teval-logloss:0.085967\n",
            "[321]\ttrain-logloss:0.005385\teval-logloss:0.086046\n",
            "[322]\ttrain-logloss:0.005379\teval-logloss:0.086091\n",
            "[323]\ttrain-logloss:0.005373\teval-logloss:0.085977\n",
            "[324]\ttrain-logloss:0.005366\teval-logloss:0.085978\n",
            "[325]\ttrain-logloss:0.00536\teval-logloss:0.085896\n",
            "[326]\ttrain-logloss:0.005354\teval-logloss:0.08578\n",
            "[327]\ttrain-logloss:0.005348\teval-logloss:0.085857\n",
            "[328]\ttrain-logloss:0.005342\teval-logloss:0.085939\n",
            "[329]\ttrain-logloss:0.005336\teval-logloss:0.085825\n",
            "[330]\ttrain-logloss:0.00533\teval-logloss:0.085869\n",
            "[331]\ttrain-logloss:0.005324\teval-logloss:0.085893\n",
            "[332]\ttrain-logloss:0.005318\teval-logloss:0.085922\n",
            "[333]\ttrain-logloss:0.005312\teval-logloss:0.085842\n",
            "[334]\ttrain-logloss:0.005306\teval-logloss:0.085735\n",
            "[335]\ttrain-logloss:0.0053\teval-logloss:0.085816\n",
            "[336]\ttrain-logloss:0.005294\teval-logloss:0.085892\n",
            "[337]\ttrain-logloss:0.005288\teval-logloss:0.085936\n",
            "[338]\ttrain-logloss:0.005283\teval-logloss:0.08583\n",
            "[339]\ttrain-logloss:0.005277\teval-logloss:0.085909\n",
            "[340]\ttrain-logloss:0.005271\teval-logloss:0.085831\n",
            "[341]\ttrain-logloss:0.005265\teval-logloss:0.085727\n",
            "[342]\ttrain-logloss:0.00526\teval-logloss:0.085678\n",
            "[343]\ttrain-logloss:0.005254\teval-logloss:0.085721\n",
            "[344]\ttrain-logloss:0.005249\teval-logloss:0.085796\n",
            "[345]\ttrain-logloss:0.005243\teval-logloss:0.085819\n",
            "[346]\ttrain-logloss:0.005237\teval-logloss:0.085715\n",
            "[347]\ttrain-logloss:0.005232\teval-logloss:0.085793\n",
            "[348]\ttrain-logloss:0.005227\teval-logloss:0.085835\n",
            "[349]\ttrain-logloss:0.005221\teval-logloss:0.085734\n",
            "[350]\ttrain-logloss:0.005216\teval-logloss:0.085658\n",
            "[351]\ttrain-logloss:0.00521\teval-logloss:0.08573\n",
            "[352]\ttrain-logloss:0.005205\teval-logloss:0.085807\n",
            "[353]\ttrain-logloss:0.0052\teval-logloss:0.085706\n",
            "[354]\ttrain-logloss:0.005195\teval-logloss:0.085659\n",
            "[355]\ttrain-logloss:0.005189\teval-logloss:0.085701\n",
            "[356]\ttrain-logloss:0.005184\teval-logloss:0.085628\n",
            "[357]\ttrain-logloss:0.005179\teval-logloss:0.085529\n",
            "[358]\ttrain-logloss:0.005174\teval-logloss:0.085604\n",
            "[359]\ttrain-logloss:0.005169\teval-logloss:0.085676\n",
            "[360]\ttrain-logloss:0.005164\teval-logloss:0.085579\n",
            "[361]\ttrain-logloss:0.005159\teval-logloss:0.085601\n",
            "[362]\ttrain-logloss:0.005153\teval-logloss:0.085643\n",
            "[363]\ttrain-logloss:0.005149\teval-logloss:0.085713\n",
            "[364]\ttrain-logloss:0.005144\teval-logloss:0.085787\n",
            "[365]\ttrain-logloss:0.005139\teval-logloss:0.085689\n",
            "[366]\ttrain-logloss:0.005134\teval-logloss:0.08573\n",
            "[367]\ttrain-logloss:0.005129\teval-logloss:0.085684\n",
            "[368]\ttrain-logloss:0.005124\teval-logloss:0.085589\n",
            "[369]\ttrain-logloss:0.005119\teval-logloss:0.085516\n",
            "[370]\ttrain-logloss:0.005114\teval-logloss:0.085588\n",
            "[371]\ttrain-logloss:0.00511\teval-logloss:0.085495\n",
            "[372]\ttrain-logloss:0.005105\teval-logloss:0.085564\n",
            "[373]\ttrain-logloss:0.0051\teval-logloss:0.085605\n",
            "[374]\ttrain-logloss:0.005096\teval-logloss:0.085626\n",
            "[375]\ttrain-logloss:0.005091\teval-logloss:0.085535\n",
            "[376]\ttrain-logloss:0.005086\teval-logloss:0.085606\n",
            "[377]\ttrain-logloss:0.005082\teval-logloss:0.085674\n",
            "[378]\ttrain-logloss:0.005077\teval-logloss:0.085714\n",
            "[379]\ttrain-logloss:0.005073\teval-logloss:0.085624\n",
            "[380]\ttrain-logloss:0.005068\teval-logloss:0.085579\n",
            "[381]\ttrain-logloss:0.005064\teval-logloss:0.085618\n",
            "[382]\ttrain-logloss:0.00506\teval-logloss:0.085639\n",
            "[383]\ttrain-logloss:0.005055\teval-logloss:0.08555\n",
            "[384]\ttrain-logloss:0.005051\teval-logloss:0.085617\n",
            "[385]\ttrain-logloss:0.005047\teval-logloss:0.085621\n",
            "[386]\ttrain-logloss:0.005042\teval-logloss:0.085551\n",
            "[387]\ttrain-logloss:0.005038\teval-logloss:0.085463\n",
            "[388]\ttrain-logloss:0.005034\teval-logloss:0.085502\n",
            "[389]\ttrain-logloss:0.005029\teval-logloss:0.085459\n",
            "[390]\ttrain-logloss:0.005025\teval-logloss:0.085321\n",
            "[391]\ttrain-logloss:0.005021\teval-logloss:0.085389\n",
            "[392]\ttrain-logloss:0.005017\teval-logloss:0.085303\n",
            "[393]\ttrain-logloss:0.005013\teval-logloss:0.085369\n",
            "[394]\ttrain-logloss:0.005009\teval-logloss:0.085301\n",
            "[395]\ttrain-logloss:0.005005\teval-logloss:0.085368\n",
            "[396]\ttrain-logloss:0.005\teval-logloss:0.085283\n",
            "[397]\ttrain-logloss:0.004996\teval-logloss:0.08532\n",
            "[398]\ttrain-logloss:0.004992\teval-logloss:0.085279\n",
            "[399]\ttrain-logloss:0.004988\teval-logloss:0.085196\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwX6hBSS1VWA"
      },
      "source": [
        "predict()를 통해 예측 확률값을 반환ㄴ하고 예측 값으로 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-wYDs8zyqkG",
        "outputId": "cecb1426-00a1-4b11-f718-d3b18f4d04cd"
      },
      "source": [
        "pred_probs = xgb_model.predict(dtest)\n",
        "print('predict()수행 결과 값을 10개만 표시, 예측 확률 값으로 표시됨')\n",
        "print(np.round(pred_probs[:10]),3)\n",
        "\n",
        "# 예측 확률이 0.5보다 크면 1, 그렇지 않으면 0으로 예측값을 결정하여 List 객체인 preds에 저장\n",
        "preds = [ 1 if x > 0.5 else 0 for x in pred_probs ]\n",
        "print('예측값 10개만 표시:',preds[:10])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predict()수행 결과 값을 10개만 표시, 예측 확률 값으로 표시됨\n",
            "[1. 0. 1. 0. 1. 1. 1. 1. 1. 0.] 3\n",
            "예측값 10개만 표시: [1, 0, 1, 0, 1, 1, 1, 1, 1, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}